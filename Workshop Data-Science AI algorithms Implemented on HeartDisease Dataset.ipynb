{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as mplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os \n",
    "import random\n",
    "from sklearn.tree import export_graphviz\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_files \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetResultDirectory = \"./\"\n",
    "dataSetFilePath = \"./DataSets/1_heart_statlog_cleveland_hungary_final.csv\"\n",
    "dataSetName = \"heart_Mix\"\n",
    "fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "missingValues = fileData.isnull().any().sum()\n",
    "print(f\"\\nNumber of Missing Values: {missingValues}\")\n",
    "\n",
    "num_rows_before = fileData.shape[0]\n",
    "# Remove duplicate records based on all columns\n",
    "fileData.drop_duplicates(inplace=True)\n",
    "# Check the number of rows after removing duplicates\n",
    "num_rows_after = fileData.shape[0]\n",
    "# Print the number of duplicate records removed\n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    " \n",
    " # Preprocess Steps from the ChatGPT\n",
    "# 1. Handling Missing Values:\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))              \n",
    "#fileData.replace({'?': np.nan}).dropna().astype(float)\n",
    "#fileData = fileData.fillna(0) \n",
    "\n",
    "fileData = fileData.fillna(0) \n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "\n",
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score', 'AUC'], ]\n",
    "\n",
    "\n",
    "dataSetResultDirectory += (\"Results_\" + dataSetName)\n",
    "dataSetResultDirectory += \"/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Classes Distribution \n",
    "target_column = \"target\" #fileData.columns.to_list()[-1]\n",
    "\n",
    "X = fileData.drop(target_column, axis=1)  # Features\n",
    "Y = fileData[target_column]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    " \n",
    "print(\"columns of x:: {} \\n\\nList of Features: {}\".format(len(X.columns), X.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of each target class\n",
    "class_distribution = fileData[target_column].value_counts()\n",
    "\n",
    "# Print the class distribution\n",
    "print(\"Target Class Distribution:\")\n",
    "print(class_distribution)\n",
    "  \n",
    "# Bar plot of class distribution\n",
    "class_distribution.plot(kind='bar', color=['skyblue', 'orange', 'green'])\n",
    "plt.title(\"Target Class Distribution\")\n",
    "plt.xlabel(\"Target Classes\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorrelationPic(correlationMatrix, numberOfTopFeatures, targetColumnName):     \n",
    "    correlation_values = correlationMatrix.abs()\n",
    "    sorted_correlation = correlation_values.unstack().sort_values(ascending=False)\n",
    "    sorted_correlation = sorted_correlation[sorted_correlation != 1.0]\n",
    "\n",
    "    num_features = numberOfTopFeatures  # Number of top features to display\n",
    "    top_features = sorted_correlation.head(num_features)\n",
    "    #print(\"Top\", num_features, \"features based on correlation:\")\n",
    "    #print(top_features)\n",
    " \n",
    "    top_features = correlationMatrix.abs().nlargest(numberOfTopFeatures, targetColumnName)[targetColumnName].index\n",
    "    top_correlation_matrix = correlationMatrix.loc[top_features, top_features]\n",
    "\n",
    "    mplot.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    # Set the title of the plot\n",
    "    mplot.title('Correlation Heatmap ({})'.format(dataSetName)  ,fontsize=16, fontweight='bold')\n",
    "    \n",
    "    picturePath = \"{}0.1_Correlation_Matrix_DateSetName_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "    \n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "def plot_classification_report(title, dataSetName, y_tru, y_prd, figsize=(6, 6), ax=None):\n",
    "    #mplot.figure(figsize=figsize)\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = ['Healthy', 'Heart Disease']\n",
    "    rep = np.array( precision_recall_fscore_support(y_tru, y_prd) ).T\n",
    "    rep[0][0] *= 100.0\n",
    "    rep[0][1] *= 100.0\n",
    "    rep[0][2] *= 100.0\n",
    "    rep[1][0] *= 100.0\n",
    "    rep[1][1] *= 100.0\n",
    "    rep[1][2] *= 100.0\n",
    "    \n",
    "    ax = sns.heatmap(rep, annot=True, cmap='Blues', cbar=False, xticklabels=xticks, yticklabels=yticks)\n",
    "    ax.set_title(\"Classification Report {} Model\\n\\n\".format(title) ,fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('\\nDataset:{}'.format(dataSetName))\n",
    "    ax.xaxis.set_ticklabels(xticks)\n",
    "    ax.set_ylabel('Classes')\n",
    "    ax.yaxis.set_ticklabels(yticks)\n",
    "    \n",
    "    picturePath = \"{}ClassificationReport_{}_{}.png\".format(dataSetResultDirectory, title, dataSetName) \n",
    "    mplot.savefig(picturePath, dpi=300, bbox_inches='tight')\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.close()\n",
    "\n",
    "    \n",
    "def makeConfusionMatrixPic(fileID, method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_predictions(y_test,predicted_Y, cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    \n",
    "    display.ax_.set_title(\"Confusion Matrix ({})\".format(method) ,fontsize=16, fontweight='bold')\n",
    "    display.ax_.set_xlabel('Predicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ') \n",
    " \n",
    "    accuracyValue = (accuracy_score(y_test, predicted_Y)*100.0) \n",
    "    recallValue = (recall_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "    precisionValue = (precision_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "    f1Score = (f1_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "\n",
    " \n",
    "    singleRowInTable = [] \n",
    "    singleRowInTable.append(fileID)\n",
    "    singleRowInTable.append(method)\n",
    "    singleRowInTable.append(\"{:.2f}\".format(accuracyValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(recallValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(precisionValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(f1Score) )\n",
    "    singleRowInTable.append(\"-\")\n",
    "\n",
    "    finalResultTable.append((singleRowInTable) )\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy : {:.2f} %\".format( accuracyValue) \n",
    "    recallString =  'Recall : {:.2f} %'.format(recallValue)\n",
    "    precisionString = 'Precision : {:.2f} %'.format(precisionValue)  \n",
    "    f1String = 'F1 Score : {:.2f} %'.format(f1Score) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "    \n",
    "    numberOfTrainingRecords = \"No of Training Records: {}  {:.2f} %\".format(len(X_train), ((len(X_train)/totalRecords) * 100.0))\n",
    "    numberOfTestingRecords = \"No of Testing Records: {}  {:.2f} %\".format(len(X_test), ((len(X_test)/totalRecords) * 100.0))\n",
    "\n",
    "\n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False , fontsize=12 )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    display.figure_.text(0.010, -0.17,  f1String, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    display.figure_.text(0.010, -0.21,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    #display.figure_.text(0.010, -0.25,  numberOfTrainingRecords, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    #display.figure_.text(0.010, -0.29,  numberOfTestingRecords, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    \n",
    "    '''\n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    '''\n",
    "    \n",
    "    picturePath = \"{}{}.Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, fileID, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "\n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "print(\"Target Column Name:: {} \\n\".format(target_column))\n",
    "  \n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "\n",
    "print(\"\\n X Train: Shape:: {}\".format(X_train.shape))\n",
    "print(\" X Test: Shape:: {}\".format(X_test.shape))   \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableAImodelResultIndex = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.     Decision Trees\n",
    "classifierDT = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=8,  random_state=18) \n",
    "classifierDT.fit(X_train_scaled, y_train) \n",
    "predicted_DT = classifierDT.predict(X_test_scaled) \n",
    "\n",
    "methodName = \"DecisionTree\" \n",
    "makeConfusionMatrixPic(tableAImodelResultIndex, methodName, dataSetName, classifierDT , X_test, y_test, predicted_DT) \n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predicted_DT)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.     Random Forests\n",
    "classifierRF = RandomForestClassifier(n_estimators=80, criterion=\"log_loss\", max_depth=8, max_features=15,n_jobs=-1, oob_score=True, bootstrap=True, random_state = 18)\n",
    "classifierRF.fit(X_train, y_train)\n",
    "y_PredictionRF = classifierRF.predict(X_test)\n",
    "\n",
    "methodName = f\"RF ({classifierRF.estimator_})\" \n",
    "#plot_classification_report(methodName, dataSetName, y_test, y_PredictionRF)  \n",
    "makeConfusionMatrixPic(tableAImodelResultIndex, methodName, dataSetName, classifierRF , X_test, y_test, y_PredictionRF)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.     Support Vector Machines (SVM)\n",
    "#classifierSVM = SVC(C=33, kernel=\"poly\") \n",
    "classifierSVM = SVC() \n",
    "classifierSVM.fit(X_train, y_train)\n",
    "y_PredictionSVM = classifierSVM.predict(X_test)\n",
    "\n",
    "methodName = \"Support Vector Machine\"\n",
    "makeConfusionMatrixPic(tableAImodelResultIndex, methodName, dataSetName, classifierSVM , X_test, y_test, y_PredictionSVM)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.     K-Nearest Neighbors (KNN)\n",
    "classifierKNN = KNN(n_neighbors=50, weights='uniform', )\n",
    "classifierKNN.fit(X_train, y_train)\n",
    "y_PredictionKNN = classifierKNN.predict(X_test)\n",
    "\n",
    "methodName = f\"K Nearest Neighbour\"\n",
    "makeConfusionMatrixPic(tableAImodelResultIndex, methodName, dataSetName, classifierKNN , X_test, y_test, y_PredictionKNN)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.     Naive Bayes (with appropriate modifications for numerical data, such as Gaussian Naive Bayes)\n",
    "classifierNB = GaussianNB(var_smoothing=0.00001 )\n",
    "classifierNB.fit(X_train, y_train)\n",
    "predicted_NB = classifierNB.predict(X_test)\n",
    "\n",
    "methodName = \"Naive Bayes\" \n",
    "makeConfusionMatrixPic(tableAImodelResultIndex, methodName, dataSetName, classifierNB , X_test, y_test, predicted_NB)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of rows in the table (excluding the header)\n",
    "num_rows = len(finalResultTable) - 1\n",
    "print(\"total Rows: {} -> Cols: {}\".format(len(finalResultTable), len(finalResultTable[0])))\n",
    "# Calculate the desired figure size based on the number of rows\n",
    "fig_width = 6  # Set the desired width of the figure\n",
    "fig_height = num_rows * 0.5  # Adjust the scaling factor to control the height\n",
    "\n",
    "fig, ax = mplot.subplots(figsize=(fig_width, fig_height)) \n",
    "table = mplot.table(cellText=finalResultTable, loc='center') \n",
    "\n",
    "table.auto_set_column_width(col=list(range(len(finalResultTable[0]))))\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12) \n",
    "table.scale(2.0, 2.0) \n",
    "\n",
    "dataSetString = \"Dataset:  {}, Total Records: {}, No. Features: {}\".format(dataSetName, X.__dataframe__().num_rows(), X.__dataframe__().num_columns())\n",
    "target =\"Target Column Name: {} , No of Classes: {}\".format(columns[-1], len(fileData[columns[-1]].value_counts()))\n",
    "distributionOfTargetClassA = \"No of Training Records: {}\".format(len(X_train))\n",
    "distributionOfTargetClassB = \"No of Testing Records: {} \".format(len(X_test))\n",
    "\n",
    "fig.text(-0.1, -0.10,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "fig.text(-0.1, -0.18,  target, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "fig.text(-0.1, -0.30,  distributionOfTargetClassA, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, -0.38,  distributionOfTargetClassB, horizontalalignment='left', wrap=False  , fontsize=12 )  \n",
    " \n",
    "mplot.axis('off')\n",
    "mplot.title(f'Final Result Table ({dataSetName})' , fontsize=16, fontweight='bold') \n",
    "picturePath = \"{}99.Final_Result_Table_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.savefig(picturePath,  dpi=300)\n",
    "mplot.show()\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
